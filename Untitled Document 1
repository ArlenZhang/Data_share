
    def p_(self, i):
        return 

    def softmax_(self, s_j, i):
        tf.divide(tf.exp(tf.matmul(tf.transpose(s_j), self.context_sents_embed[i])),
                  tf.add_n([tf.exp(tf.matmul(tf.transpose(s_k), self.context_sents_embed[i])) for s_k in
                            self.target_sents_embed[i]]))
        return True

    def _create_loss(self):
        with tf.name_scope('loss'):
            l_ = tf.add_n([tf.add_n([tf.multiply(self.self.target_pos_neg_flag[i], tf.log(
			tf.divide(tf.exp(tf.matmul(tf.transpose(s_j), self.context_sents_embed[i])),
                  tf.add_n([tf.exp(tf.matmul(tf.transpose(s_k), self.context_sents_embed[i])) for s_k in
                            self.target_sents_embed[i]]))
			)) for s_j in self.target_sents_embed[i]])] for i in self.batch_size)
            
			self.loss = tf.multiply(-1, l_)

